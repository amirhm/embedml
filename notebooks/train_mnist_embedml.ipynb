{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as Tf\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedml.tensor import Tensor\n",
    "from embedml.nn import Linear\n",
    "from embedml.nn import Module\n",
    "from embedml.nn import Softmax, LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.MNIST('data', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        super().__init__()\n",
    "        self.len = len(data)\n",
    "        self.data = data.view((-1, 28 * 28)).float()\n",
    "        self.data = (self.data - self.data.mean(axis=-1, keepdim=True)) / self.data.std(axis=-1, keepdim=True)\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds , test_ds = (ds.data[:50000], ds.targets[:50000]) , (ds.data[50000:], ds.targets[50000:])\n",
    "train = dataset(*train_ds)\n",
    "eval = dataset(*test_ds)\n",
    "\n",
    "t_dl = DataLoader(train, batch_size=64, drop_last=True)\n",
    "e_dl = DataLoader(eval, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = Linear(28*28, 32)\n",
    "        self.l2 = Linear(32, 10)\n",
    "        self.ac = LogSoftmax(dim=1)\n",
    "    def forward(self, data):\n",
    "        y0 = self.l1(data)\n",
    "        y1 = self.ac(self.l2(y0))\n",
    "        return y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label, num_classes):\n",
    "    shape = label.shape[0], num_classes\n",
    "    y = np.zeros(shape)\n",
    "    y_ptr = y.reshape((-1,))\n",
    "    idx = label.flatten() + np.arange(0, (np.prod(shape)), shape[1])\n",
    "    y_ptr[idx] = 1\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class optim:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = Tensor(np.array(lr))\n",
    "        \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param -= param.grad * self.lr\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.grad = param.grad * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = m.get_parameters()\n",
    "opt = optim(p, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(p)):\n",
    "    p[i].data = p[i].data * 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(test_ds[1])\n",
    "t = Tensor(test_ds[0].reshape((-1, 784)), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_h = []\n",
    "\n",
    "for x, l in t_dl:\n",
    "    x = Tensor(x, requires_grad=False)\n",
    "    y = m(x)\n",
    "    T = Tensor(one_hot(l, 10), requires_grad=False)\n",
    "    loss = (y * T).sum() * -1\n",
    "    loss.backward()   \n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    label = m(t).data.argmax(axis=-1)\n",
    "    acc = (label == target).sum() * 100 / target.shape\n",
    "    loss_h.append((loss.data[0], acc))\n",
    "print(f\"{acc=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array(loss_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p[:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "43d6bd1c65c6ab83354115e7642f714072bd96c4fdb04d6156b888e4b0ae4cae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
